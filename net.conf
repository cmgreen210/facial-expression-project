netconfig = start
layer[0->1] = conv
  init_random = gaussian
  padding = 1
  stride = 1
  num_channels = 32
  num_groups = 1
  kernel_size = 3
layer[1->2] = relu
layer[2->3] = conv
  init_random = gaussian
  padding = 1
  stride = 1
  num_channels = 64
  num_groups = 1
  kernel_size = 3
layer[3->4] = relu
layer[4->5] = max_pooling
  padding = 0
  stride = 2
  kernel_size = 2
layer[5->6] = flatten
layer[6->7] = fullc
  init_sigma = 0.01
  init_random = gaussian
  init_bias = 0
  num_hidden_units = 1024
layer[7->8] = relu
layer[8->9] = dropout
  threshold = 0.5
layer[9->10] = fullc
  init_sigma = 0.01
  init_random = gaussian
  init_bias = 0
  num_hidden_units = 3
layer[10->11] = softmax
netconfig = end

## network parameters
learning_rate = 0.01
subtract_mean = True
batch_size = 256
learning_rate_schedule = polynomial_decay
learning_rate_alpha = 1.0
random_mirror = True
l2_regularization = 0.001
momentum = 0.5
## end network parameters
